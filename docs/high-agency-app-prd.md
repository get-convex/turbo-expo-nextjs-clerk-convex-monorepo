## 1) Latest research and protocols for becoming a “high agency” person

“High agency” isn’t a single standardized clinical construct, so the most defensible approach is to treat it as a _stack_ of trainable capacities that jointly produce “I reliably initiate, choose, and persist in goal‑directed action.” The best-supported levers map to: **self‑efficacy**, **perceived control/locus of control**, **proactivity/personal initiative**, **autonomous motivation/internalization**, **habit automaticity**, and **identity processes**.

### A. Self‑efficacy as a core driver (and it’s trainable)

A large 2025 systematic review/meta-analysis of internet-based interventions (70 studies; N≈17k) found **moderate improvements in self-efficacy** (between-group d≈0.46), with **guided interventions showing larger effects** (d≈0.66). ([ScienceDirect][1])

**Protocol implications**

- **Guidance matters** (coaching, feedback, accountability). If you want a self-built “agency” system to work long-term, it should behave less like a static tracker and more like a _guided_ program (your AI can be that guide).
- Build self-efficacy through **graduated mastery**: repeated small wins that escalate difficulty.

### B. Perceived control / locus of control as a behavioral amplifier

A 2024 systematic review on health locus of control (HLOC) and behavioral interventions concludes that **higher internal HLOC predicts more consistent engagement in beneficial behaviors**, while **high “chance” HLOC predicts poorer preventive adherence**, and proposes guidelines that—_in many situations_—increasing internal control beliefs improves outcomes. ([IJMR][2])

**Protocol implications**

- Train “control beliefs” by repeatedly converting ambiguous situations into: **(1) what’s controllable**, **(2) what action is available**, **(3) what feedback will be observed**.

### C. Proactivity / “personal initiative” training has unusually strong real-world evidence

A World Bank working paper (2024) revisiting a randomized experiment in Togo reports long-lasting impacts of **personal initiative training** (psychology-based proactive mindset training) years later. The training aims to build a **self-starting, future-oriented, persistent proactive mindset**, with exercises around **innovation**, **learning from setbacks**, and differentiation. ([Innovations for Poverty Action][3])
A World Bank blog summary (2025) reiterates large medium-term gains and describes the training as focusing on behaviors associated with a proactive mindset, not just “business practices.” ([World Bank Blogs][4])

**Protocol implications (generalized beyond entrepreneurship)**

- Adopt a weekly “initiative project” that is **self-started**, **future-oriented**, and requires **barrier‑overcoming** behavior.
- Encode setbacks as _inputs_ for iteration (a learned “initiative loop”), not as identity evidence of failure.

### D. Psychological Capital (hope/efficacy/resilience/optimism) can be increased—and effects can last

A “most up-to-date” PsyCap intervention meta-analysis (40 studies; N≈4,207) reports interventions improve PsyCap components, with stronger impacts on **hope and optimism**; and reports **sustained positive effects** for PsyCap, hope, resilience, and optimism (with nuance: not all components sustain equally; session frequency matters). ([ScienceDirect][5])

**Protocol implications**

- Include a _hope protocol_: define goal, define pathways, define contingency pathways (what you do when blocked).
- Include _resilience protocol_: convert setbacks into an “after‑action review” and a new obstacle plan.

### E. Sustained agency requires internalization, not just “engagement with the app”

A 2024 open-access review of Self‑Determination Theory (SDT) in behavior change technologies warns that BCTs often fail long-term and can **backfire**; it argues many designs optimize engagement _with the technology_ rather than internalizing motivation toward the _target behavior_, and points to SDT’s Organismic Integration Theory as a better lens for long-term internalization. ([OUP Academic][6])

**Protocol implications**

- Your system should explicitly support:
  - **Autonomy**: you choose the commitments (the AI helps you choose, but doesn’t decide).
  - **Competence**: calibrated challenge + mastery evidence.
  - **Internalization**: repeated “why this matters” linking to values, not only streaks/rewards.

### F. Habit formation and automaticity: timelines are longer and more variable than popular lore

A 2024 systematic review/meta-analysis on health habit formation reports median times to automaticity around **~59–66 days**, mean times **~106–154 days**, and **very large variability** (4–335 days). It also notes determinants like frequency, timing, habit type, _individual choice_, affect, behavioral regulation, and preparatory habits; morning practice and self-selected habits tend to show greater strength. ([PMC][7])

**Protocol implications**

- Design for a **2–6 month runway**, not “21 days.”
- Focus on **context-stable repetition**, and bias toward **self-chosen** habits.

### G. Identity change is real but typically modest; behavior change usually leads

A 2025 meta-analysis on identity interventions for physical activity finds that interventions produce **small-to-medium effects on behavior**, and **smaller changes in identity** (with identity effects smaller than behavior effects), while emphasizing that identity is both stable and changeable. ([PubMed][8])

**Protocol implications**

- Treat identity as **lagging indicator** and **evidence accumulation**: “I’m becoming the kind of person who does X” after repeated actions and reflection, not as a purely verbal mantra.

---

### A consolidated “High‑Agency Protocol” (designed to be app‑implementable)

This is written as an explicit routine the app can run daily/weekly.

**Daily (10–15 minutes total)**

1. **One Initiative Commitment (2 minutes)**
   Pick 1 self-started action that moves your future forward (project, skill, relationship, health). Must be _small enough to finish today_.
   _Rationale_: initiative training emphasizes self-starting + future orientation + barrier overcoming. ([Innovations for Poverty Action][3])

2. **If‑Then Obstacle Plan (2–4 minutes)**
   For the initiative action, write an _if‑then_:
   - “If it’s 09:00 and I finish coffee, then I open X and do the first 5 minutes.”
   - “If I feel resistance, then I do the 60‑second starter.”
     (The app can generate and you approve.)

3. **Guided Micro‑Execution (3–8 minutes)**
   Start a time‑boxed sprint with coaching. The meta-analysis suggests guided formats improve self-efficacy more than unguided. ([ScienceDirect][1])

4. **Evidence Log (2 minutes)**
   Record: did I do it? what blocked me? what did I learn? what’s the next micro-step?
   This builds perceived control and competence; it also produces “identity evidence” gradually. ([IJMR][2])

**Weekly (30–45 minutes)**

- **Agency Retrospective**
  - Review initiative actions completed, identify “barrier patterns.”
  - Choose one pattern to address with a new environment/cue change.
  - Set one “next week initiative project.”
  - Review values + re‑internalize why (SDT internalization). ([OUP Academic][6])

**Monthly**

- Re-assess with brief scales (self-efficacy, perceived control, habit automaticity) and adjust difficulty.

---

## 2) Latest research on designing engaging, minimal apps that change behavior

### A. The behavior-change toolbox that correlates with engagement

A 2023 systematic review identified behavior change techniques (BCTs) most associated with engagement, including **goal setting**, **self-monitoring**, **feedback**, **prompts/cues**, **rewards**, and **social support**. ([Frontiers][9])

For a minimal app, this implies: you can get most of the “engagement lift” from a small set of primitives—without feature sprawl.

### B. What habit-formation digital interventions actually do in practice

A 2024 JMIR systematic review of _habit formation designs in digital behavior change interventions_ found common strategies like:

- habit techniques built around **intentions, cues, and positive reinforcement**
- **automatic monitoring**, **descriptive feedback**
- **time-based cues**, **virtual rewards**
  It also flags gaps: fewer implicit interaction strategies, and ethical attention around users not realizing how tracking influences them. ([JMIR][10])

### C. Habit formation timelines must inform product expectations

If median automaticity is around ~2 months but can extend much longer for many people, the app should be designed as a **longitudinal training system** rather than a short sprint challenge. ([PMC][7])

Design implication: plan for **first-2-weeks dropout risk**, **weeks 3–8 habit strengthening**, and **months 3–6 consolidation**.

### D. JITAI design: deliver the “right support at the right time”

A 2024 scoping review of just-in-time adaptive interventions (JITAIs) reports 62 JITAIs across many behaviors; many studies focus on feasibility/usability, and tailoring often relies on self-report (55%), sometimes passive data only. The paper summarizes JITAI structure with six components: distal outcome, proximal outcomes, decision points, tailoring variables, intervention options, and decision rules. ([eprints.soton.ac.uk][11])

Design implication: the “minimal app” can still be _highly personalized_ if it:

- defines **decision points** (when to intervene)
- learns **tailoring variables** (signals that predict opportunity/vulnerability)
- keeps **intervention options** few but context-sensitive

### E. Engagement/retention reality check

A 2024 narrative review notes engagement is highly variable and warns against simplistic “more usage = better.” It reports typical patterns: heavy early usage, sharp drop in first weeks, then leveling; it cites data where median 15-day retention across 93 mental health apps was 3.9% and median 30-day retention 3.3%. It recommends defining success by **outcomes**, and exploring different clusters/patterns rather than assuming one-size-fits-all engagement. ([Springer][12])

Design implication: your app’s KPI should be **agency gains**, not time-in-app.

### F. Neuroscience/habit learning: formation and breaking require different tactics

A 2024 review in neuroscience frames habits as a balance between goal-directed and stimulus-driven systems; it describes how habits are acquired and expressed, and discusses breaking habits via changing cue exposure, strengthening goal-directed control, and competing responses. ([ScienceDirect][13])

Design implication:

- To **build** agency habits: stable cues + repetition + reinforcement.
- To **break** anti-agency patterns: cue management + substitute actions + inhibition support.

### G. LLMs as behavior-change infrastructure (emerging work)

A 2025 arXiv paper (“Bloom”) discusses designing for LLM-augmented behavior change, explicitly connecting LLM interaction patterns with behavior change techniques. ([arXiv][14])

Design implication: GPT‑5.2-class models can implement “guidance” cheaply and continuously, enabling the stronger effects seen in guided interventions. ([ScienceDirect][1])

---

## 3) PRD: Minimal but highly effective “Agency OS” mobile app

### 3.1 Product overview

**Product name (working):** Agency OS
**Platform:** iOS first (Android later)
**Primary objective:** Increase the user’s personal agency over time by improving:

- reliable initiation of meaningful actions
- persistence through barriers
- perceived control and self-efficacy
- habit automaticity for “agency behaviors”
- internalized, identity-consistent goal pursuit

**Why this can be minimal:** The app is essentially a **guided daily loop** + **context-aware nudges** + **reflection-driven personalization**. Research suggests you do not need many features—just the right ones (goal setting, monitoring, feedback, prompts, rewards) used well. ([Frontiers][9])

### 3.2 Target user

Single-user (you). Assume:

- high ambition, inconsistent execution
- wants strong personalization
- willing to grant broad permissions and collect sensitive data
- wants long-term improvement (months), not novelty

### 3.3 Problem statement

Even with clear goals, you experience:

- action initiation friction
- procrastination loops
- inconsistent follow-through under stress/low energy
- low leverage planning (busy, not effective)
- weak feedback loops (you don’t learn systematically from what works)

### 3.4 Core insight from research (design constraints)

1. Agency gains require **guided mastery experiences** (guidance tends to increase self-efficacy gains). ([ScienceDirect][1])
2. Habit formation takes **weeks to months** and varies widely. ([PMC][7])
3. JITAIs provide a structure for “right time, right support.” ([eprints.soton.ac.uk][11])
4. Engagement should be defined by **outcomes**, not time-in-app. ([Springer][12])
5. Support **internalization** (autonomy/competence), or the system may backfire long-term. ([OUP Academic][6])

---

### 3.5 Product principles

1. **One primary daily commitment** (avoid overwhelming plans).
2. **Guided, not controlling**: the AI recommends; you approve.
3. **Context-aware, low-noise prompting**: fewer notifications, better timed.
4. **Outcome-first metrics**: agency improvements > engagement metrics. ([Springer][12])
5. **Evidence accumulation**: actions → reflection → personalized rules → identity shift. ([PubMed][8])
6. **Local-first privacy by architecture**, even if you choose to collect everything (encryption, explicit data scopes).

---

### 3.6 MVP scope

#### MVP: 3-screen app

**Screen A — “Today” (60 seconds)**

- Shows **One Initiative Commitment** (the one thing that increases agency most today).
- Shows “Start” button (launches guided sprint).
- Shows next scheduled “decision point” check-in.

**Screen B — “Start Sprint” (guided execution)**

- 5–25 minute time-boxed execution.
- AI breaks the task into smallest next step.
- Friction reducers: “60-second starter,” “micro-commitment,” “environment suggestion.”

**Screen C — “Close Loop” (2-minute reflection)**

- Did you do it? Y/N/Partial.
- What blocked you? (select + free text)
- What worked? (select + free text)
- Auto-generated next-day adjustment (you approve).

This implements the most engagement-linked BCT set with minimal UI: goal setting, self-monitoring, prompts/cues (in the right context), and feedback. ([Frontiers][9])

---

### 3.7 Detailed functional requirements

#### FR1 — Initiative Commitment Generator (daily)

- Inputs:
  - your goals/values (stored)
  - calendar availability
  - current projects
  - energy/mood (optional self-report)
  - context signals (see data section)

- Output:
  - 1 initiative action with:
    - clear “done” definition
    - estimated time
    - suggested cue/context (“when/where”)
    - obstacle plan draft (“if X then Y”)

- Must support **autonomy**: user can edit/replace and must explicitly accept. (SDT internalization.) ([OUP Academic][6])

#### FR2 — If‑Then Plan Builder

- Converts commitment into:
  - _cue_: time/location/event-based
  - _starter step_: <60 seconds
  - _fallback plan_: smallest salvage action

- Stores “what worked” and learns.

#### FR3 — JITAI Nudge Engine (minimal version)

- Decision points:
  - wake window (e.g., 30–90 min after waking)
  - pre-commitment window (before first meeting)
  - “procrastination detection” window (when screen time spikes)
  - evening close-loop window

- Tailoring variables (start minimal; expand):
  - calendar free/busy
  - location (home/office/out)
  - phone state (focus mode / do not disturb)
  - recent screen time category shifts
  - physiological state proxy (sleep/HRV) if available

- Intervention options (keep very few):
  1. “Start 60 seconds now?”
  2. “Rescope to smallest meaningful action?”
  3. “Schedule a protected block?”

- Decision rules:
  - simple heuristics initially
  - later: learned policy (micro-randomized or n-of-1 tuning) consistent with JITAI structure. ([eprints.soton.ac.uk][11])

#### FR4 — Guided Sprint (AI coach)

- Starts a timer and an action script:
  - step 1: open X
  - step 2: do Y for 3 minutes
  - step 3: checkpoint

- Adaptive:
  - if user stalls → offers smaller step
  - if user succeeds → offers slight escalation (competence building)

Rationale: “guided” interventions show larger self-efficacy effects than unguided; your AI approximates “guidance.” ([ScienceDirect][1])

#### FR5 — Evidence Log + Weekly Review

- Daily evidence log (micro)
- Weekly review (macro):
  - summarize wins/failures
  - identify repeating barriers
  - produce one “barrier strategy” for next week (environment/cue/plan change)

---

### 3.8 Data collection and use (aggressive, personal-only)

Because this is personal, you can collect broadly, but design it as **modular scopes** so you can toggle sources without breaking the system.

#### Data sources (suggested)

1. **Self-report**
   - quick mood/energy (1–2 taps)
   - perceived control rating (“I felt in control today” 1–7)
   - short journal or voice note

2. **Device behavior**
   - screen time by category
   - app launches
   - notifications received/cleared
   - focus mode / DND

3. **Calendar & tasks**
   - meetings, free blocks, deadlines
   - task list + completion

4. **Location & movement**
   - significant location changes
   - step count, activity state

5. **Biometrics (optional)**
   - sleep duration/quality (Apple Health / Google Fit)
   - heart rate, HRV proxies

6. **Personal knowledge base**
   - notes, documents, read-it-later
   - project folders

7. **Communications (optional; high sensitivity)**
   - message metadata (timing, volume)
   - content _only if you explicitly choose_ and store securely

#### Data use cases

- Detect “agency opportunities” (free time + adequate energy).
- Detect “agency vulnerability” (late night, poor sleep, high distraction).
- Personalize prompts to reduce noise.
- Build a model of what interventions actually work (your own n-of-1 evidence).

**Important constraint:** Many apps fail from early dropout; your prompts must be sparse and high-precision. ([Springer][12])

#### Storage/security (even for personal use)

- Local encrypted database (device keychain / secure enclave where possible)
- Optional encrypted cloud backup
- Separate raw data vs derived features
- Explicit data retention policy (e.g., raw location traces auto-delete after N days; keep aggregates)

---

### 3.9 AI architecture (assuming GPT‑5.2‑class models)

**Core components**

1. **Personal Model (Memory + Preferences)**
   - stable: values, goals, identity statements, constraints
   - dynamic: recent performance, energy patterns, barriers
   - stored in a local DB + vector store

2. **Planner**
   - generates daily initiative action candidates
   - chooses one based on predicted payoff and feasibility

3. **Coach**
   - runs guided sprints
   - generates obstacle plans
   - uses motivational style tuned for autonomy support (avoid controlling language). ([OUP Academic][6])

4. **JITAI Policy**
   - predicts best intervention option at each decision point
   - initially heuristic; later learned via within-user experiments consistent with JITAI framing. ([eprints.soton.ac.uk][11])

5. **Evaluator**
   - reads evidence log
   - updates what works
   - produces weekly review

**Guardrails (practical)**

- Never fabricate calendar facts; always reference actual data.
- If uncertain, ask for confirmation in-app (“Is this the right time?”) rather than guessing.
- “Do less harm” defaults: if user is stressed/low energy, prefer rescope vs push.

---

### 3.10 UX requirements (minimal + engaging without addiction)

1. **Time-to-value < 60 seconds** on day 1
   User should complete their first initiative action or first guided sprint immediately.

2. **No feeds, no infinite scroll, no streak pressure as primary mechanic**
   SDT review suggests reliance on app enjoyment/engagement can undermine long-term behavior change. ([OUP Academic][6])

3. **Notification budget**
   - default: 2 per day max
   - only if probability of compliance is high (context-aware)

4. **“Outcome dashboard” (weekly, not daily)**
   - show agency outcomes, not engagement
   - trends: initiative completions, perceived control, self-efficacy proxy

---

### 3.11 Success metrics

Because engagement ≠ success, define success on outcomes. ([Springer][12])

**Primary**

- Increase in weekly “initiative completion rate”
- Increase in perceived control rating
- Increase in self-efficacy (periodic short scale)
- Increase in habit automaticity for 1–3 agency habits (SRBAI/SRHI-style measures referenced in habit research) ([PMC][7])

**Secondary**

- Reduction in procrastination proxy (late-night screen time; “time-to-start” after a free block)
- Reduced variance in follow-through under stress (stability metric)

**Guardrail**

- User-reported feeling of autonomy (avoid coercive experience). ([OUP Academic][6])

---

### 3.12 Experimentation plan (single-user, high power)

1. **Baseline period (7–14 days)**
   Track without nudges to establish natural rhythms.

2. **Micro-randomization for nudges (optional)**
   At decision points, randomly choose between:
   - nudge vs no nudge
   - nudge type A vs B
     Evaluate proximal outcomes (e.g., started within 10 minutes). This aligns with JITAI evaluation logic referenced in the review discussion of tailoring/decision rules. ([eprints.soton.ac.uk][11])

3. **A/B prompt style: autonomy-supportive vs directive**
   Monitor adherence and subjective autonomy.

---

### 3.13 Risks and mitigations

1. **Over-notification → uninstall / avoidance**
   - strict notification budget
   - context-aware only

2. **“App dependency” instead of internalized agency**
   - progressive fading: after habits strengthen, reduce prompts
   - emphasize internalization (why/values) and competence evidence. ([OUP Academic][6])

3. **Misleading AI guidance**
   - require explicit acceptance for commitments
   - keep logs of AI suggestions and outcomes for self-audit

4. **Privacy/security exposure due to broad data ingestion**
   - encryption, local-first, modular scopes, clear retention policy

---

## Appendix: Minimal feature → evidence mapping

- **One daily initiative goal + “done” definition** → goal setting (engagement-linked BCT) ([Frontiers][9])
- **Guided sprint** → “guided” format linked to stronger self-efficacy gains in digital interventions ([ScienceDirect][1])
- **Context-aware nudges** → JITAI structure and rationale ([eprints.soton.ac.uk][11])
- **Two-minute reflection + weekly review** → feedback/self-monitoring (engagement-linked BCT) ([Frontiers][9])
- **Months-long runway + expectation setting** → habit automaticity timelines and variability ([PMC][7])
- **Identity as evidence accumulation** → identity intervention effects smaller than behavior; identity lags ([PubMed][8])

If you want, I can also convert the PRD into:

- a Jira-ready backlog (epics → user stories → acceptance criteria), or
- a technical architecture spec (data schemas, retrieval/memory design, on-device vs cloud split).

[1]: https://www.sciencedirect.com/science/article/pii/S2214782925000223 "https://www.sciencedirect.com/science/article/pii/S2214782925000223"
[2]: https://www.i-jmr.org/2024/1/e52287/ "https://www.i-jmr.org/2024/1/e52287/"
[3]: https://poverty-action.org/sites/default/files/2025-07/IDU1738abbbc1f83d14a1e19bd718610cf96c99e%20%283%29.pdf "https://poverty-action.org/sites/default/files/2025-07/IDU1738abbbc1f83d14a1e19bd718610cf96c99e%20%283%29.pdf"
[4]: https://blogs.worldbank.org/en/impactevaluations/personal-initiative-training-continues-to-yield-positive-benefit "Personal initiative training continues to yield positive benefits after 7 years, but impacts vary with gender"
[5]: https://www.sciencedirect.com/org/science/article/pii/S0048348624000505 "https://www.sciencedirect.com/org/science/article/pii/S0048348624000505"
[6]: https://academic.oup.com/iwc/advance-article/doi/10.1093/iwc/iwae040/7760010 "https://academic.oup.com/iwc/advance-article/doi/10.1093/iwc/iwae040/7760010"
[7]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11641623/ "https://pmc.ncbi.nlm.nih.gov/articles/PMC11641623/"
[8]: https://pubmed.ncbi.nlm.nih.gov/40008714/ "https://pubmed.ncbi.nlm.nih.gov/40008714/"
[9]: https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1227443/full "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1227443/full"
[10]: https://www.jmir.org/2024/1/e54375/ "https://www.jmir.org/2024/1/e54375/"
[11]: https://eprints.soton.ac.uk/496347/1/British_J_Health_Psychol_-_2024_-_Hsu_-_Personalized_interventions_for_behaviour_change_A_scoping_review_of_just_in_time.pdf "https://eprints.soton.ac.uk/496347/1/British_J_Health_Psychol_-_2024_-_Hsu_-_Personalized_interventions_for_behaviour_change_A_scoping_review_of_just_in_time.pdf"
[12]: https://link.springer.com/article/10.1186/s44247-024-00105-9 "https://link.springer.com/article/10.1186/s44247-024-00105-9"
[13]: https://www.sciencedirect.com/science/article/pii/S1364661324002663 "https://www.sciencedirect.com/science/article/pii/S1364661324002663"
[14]: https://arxiv.org/html/2510.05449v1 "https://arxiv.org/html/2510.05449v1"
